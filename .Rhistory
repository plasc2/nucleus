# t.lodes <- t.lodes[t.lodes$D_KM <= h.maxdistance, ] # UPDATE: Decide whether to keep this or not
# May not be needed, just say that the max distance represents that maximum site pool radius
# However, if the edge of the site pool intersects large units which draw their centroids far beyond the pool, this can lead to excessively large average distances with not unit sample sizes
t.lodes <- t.lodes %>% select(-C_HOME_LAT, -C_HOME_LON, -C_WORK_LAT, -C_WORK_LON)
if (h.osrmapply == TRUE) {
f.message(type = "MESSAGE", message = "Predicting OSRM values.", write = FALSE, adjustment = 3/3)
t.lodes$D_KM_SQRT <- sqrt(t.lodes$D_KM)
t.lodes$D_KM_OSRM <- predict(m.dist, newdata = t.lodes)
t.lodes$D_KM_OSRM[t.lodes$D_KM_OSRM < 0] <- 0
t.lodes$TIME_OSRM <- predict(m.time, newdata = t.lodes)
t.lodes$TIME_OSRM[t.lodes$TIME_OSRM < 0] <- 0
}
if (sum(grepl("Site Pool", list.files(p.resultssite))) == 0) {
f.message(type = "MESSAGE", message = paste0("Writing site pool image to: ", p.resultssite), write = FALSE, adjustment = 3/3)
if (f.levelfromalias(a.agg) %in% f.levelfromalias(c("CBSA", "CSA", "MSA")) | f.levelfromalias(a.agg) <= f.levelfromalias("State")) {
t.plot <- ggplot() +
geom_sf(data = k.states[!k.states$CODE %in% h.cull, ], fill = "white", color = NA) +
geom_sf(data = s.pool, fill = NA, color = "lightgray") +
geom_sf(data = k.states[!k.states$CODE %in% h.cull, ], fill = NA, color = "#545454") +
geom_sf(data = s.agg, color = h.accent.1, fill = NA, linewidth = 0.5) +
geom_sf(data = st_buffer(s.agg, dist = h.maxdistance * 1000), color = h.accent.1, fill = "NA", linetype = "dashed") +
theme(
plot.title    = element_text(hjust = 0.5, face = "bold", size = 14),
plot.subtitle = element_text(hjust = 0.5, size = 12),
plot.caption  = element_text(hjust = 0.5, size = 10, color = h.accent.1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.x = element_blank(),
axis.ticks.y = element_blank()
) +
coord_sf(xlim = st_bbox(s.pool)[c("xmin", "xmax")],
ylim = st_bbox(s.pool)[c("ymin", "ymax")]) +
labs(
title = "Site Pool",
subtitle = paste0(i.sitename, ", ", i.year),
caption = paste0(h.maxdistance, "km radius")
)
} else {
t.plot <- ggplot() +
geom_sf(data = k.states, fill = "white", color = NA) +
geom_sf(data = s.pool, fill = NA, color = "lightgray") +
geom_sf(data = k.states, fill = NA, color = "#545454") +
geom_sf(data = s.agg, fill = h.accent.1, color = NA) +
geom_sf(data = st_buffer(s.agg, dist = h.maxdistance * 1000), color = h.accent.1, fill = "NA", linetype = "dashed") +
theme(
plot.title    = element_text(hjust = 0.5, face = "bold", size = 14),
plot.subtitle = element_text(hjust = 0.5, size = 12),
plot.caption  = element_text(hjust = 0.5, size = 10, color = h.accent.1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.x = element_blank(),
axis.ticks.y = element_blank()
) +
coord_sf(xlim = st_bbox(s.pool)[c("xmin", "xmax")],
ylim = st_bbox(s.pool)[c("ymin", "ymax")]) +
labs(
title = "Site Pool",
subtitle = paste0(i.sitename, ", ", i.year),
caption = paste0(h.maxdistance, "km radius")
)
}
suppressWarnings(ggsave(file.path(p.resultssite, paste0("Site Pool - ", toupper(i.sitename), " - ", i.year, ".", h.device)), plot = t.plot, device = h.device, units = "px", height = 2000, width = 2000))
rm(t.plot)
}
# By segment and OSRM ----
i.segment <- a.segment.adj[1] # Debugging
for (i.segment in a.segment.adj) {
f.message(type = "MESSAGE", message = "Beginning segment-level analysis.", write = FALSE, adjustment = 1/10)
if (sum(grepl("Network Distance", i.segment)) == 1) {
i.segment.tag <- "D_KM_OSRM"
i.segment.clean <- gsub(" \\(Network Distance\\)", "", i.segment)
} else if (sum(grepl("Network Time", i.segment)) == 1) {
i.segment.tag <- "TIME_OSRM"
i.segment.clean <- gsub(" \\(Network Time\\)", "", i.segment)
} else {
i.segment.tag <- "D_KM"
i.segment.clean <- i.segment
}
# Divide inclusive and exclusive routes
f.message(type = "MESSAGE", message = "Splitting inclusive and exclusive LODES OD routes.", write = FALSE, adjustment = 1/10)
t.lodes.incl <- t.lodes %>% select(all_of(c("HOME", "WORK", i.segment.clean, i.segment.tag))) %>% filter(HOME %in% s.units$GEOID & WORK %in% s.units$GEOID)
t.lodes.excl <- t.lodes %>% select(all_of(c("HOME", "WORK", i.segment.clean, i.segment.tag))) %>% filter(!(HOME %in% s.units$GEOID & WORK %in% s.units$GEOID))
if (nrow(t.lodes.incl) == 0) {
f.message(type = "WARNING", code = "W-00012", message = paste0("LODES data for '", o.sites$STATE[i.site], "', year ", i.year, " potentially corrupted. No site-inclusive routes returned. Skipping to next segment."))
Sys.sleep(3)
next
}
names(t.lodes.incl)[3] <- "NUM"
names(t.lodes.excl)[3] <- "NUM"
names(t.lodes.incl)[4] <- "QUER"
names(t.lodes.excl)[4] <- "QUER"
tic()
# Open the write tables
f.message(type = "MESSAGE", message = "Reading output files.", write = FALSE, adjustment = 2/10)
t.read <- list.files(file.path(p.resultssite, i.segment))
t.aggregateprofile <- read.csv(file.path(p.resultssite, i.segment, t.read[grepl("Aggregate Profile", t.read)]))
t.unitprofile <- read.csv(file.path(p.resultssite, i.segment, t.read[grepl("Unit Profile", t.read)]))
rm(t.read)
t.units <- s.units
f.message(type = "MESSAGE", message = "Calculating OD statistics.", write = TRUE, adjustment = 3/10)
# Calculate EED and other statistics
f.message(type = "MESSAGE", message = paste0("Calculating 'D_IN'. Estimated time remaining: ", ifelse((nrow(t.lodes.excl) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes.excl) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes.excl) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 4/10)
t.units$D_IN <- mapply(function(geoid) {
i <- which(t.lodes.excl$WORK == geoid)
weights <- t.lodes.excl$NUM[i]
distances <- t.lodes.excl$QUER[i]
sum(distances * weights, na.rm = TRUE) / sum(weights, na.rm = TRUE)
}, s.units$GEOID)
f.message(type = "MESSAGE", message = paste0("Calculating 'D_OUT'. Estimated time remaining: ", ifelse((nrow(t.lodes.excl) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes.excl) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes.excl) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 5/10)
t.units$D_OUT <- mapply(function(geoid) {
i <- which(t.lodes.excl$HOME == geoid)
weights <- t.lodes.excl$NUM[i]
distances <- t.lodes.excl$QUER[i]
sum(distances * weights, na.rm = TRUE) / sum(weights, na.rm = TRUE)
}, s.units$GEOID)
f.message(type = "MESSAGE", message = paste0("Calculating 'T_IN'. Estimated time remaining: ", ifelse((nrow(t.lodes.excl) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes.excl) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes.excl) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 6/10)
t.units$T_IN <- mapply(function(geoid) {
if (geoid %in% t.lodes.excl$WORK) {
sum(t.lodes.excl$NUM[t.lodes.excl$WORK == geoid], na.rm = TRUE)
} else {
NA
}
}, t.units$GEOID)
f.message(type = "MESSAGE", message = paste0("Calculating 'T_OUT'. Estimated time remaining: ", ifelse((nrow(t.lodes.excl) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes.excl) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes.excl) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 7/10)
t.units$T_OUT <- mapply(function(geoid) {
if (geoid %in% t.lodes.excl$HOME) {
sum(t.lodes.excl$NUM[t.lodes.excl$HOME == geoid], na.rm = TRUE)
} else {
NA
}
}, t.units$GEOID)
f.message(type = "MESSAGE", message = paste0("Calculating 'D_SELF_IN'. Estimated time remaining: ", ifelse((nrow(t.lodes.incl) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes.incl) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes.incl) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 8/10)
t.units$D_SELF_IN <- mapply(function(geoid) {
i <- which(t.lodes.incl$WORK == geoid)
weights <- t.lodes.incl$NUM[i]
distances <- t.lodes.incl$QUER[i]
sum(distances * weights, na.rm = TRUE) / sum(weights, na.rm = TRUE)
}, s.units$GEOID)
f.message(type = "MESSAGE", message = paste0("Calculating 'D_SELF_OUT'. Estimated time remaining: ", ifelse((nrow(t.lodes.incl) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes.incl) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes.incl) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 9/10)
t.units$D_SELF_OUT <- mapply(function(geoid) {
i <- which(t.lodes.incl$HOME == geoid)
weights <- t.lodes.incl$NUM[i]
distances <- t.lodes.incl$QUER[i]
sum(distances * weights, na.rm = TRUE) / sum(weights, na.rm = TRUE)
}, s.units$GEOID)
t.lodes.temp <- t.lodes %>% select(all_of(c("HOME", "WORK", i.segment.clean, i.segment.tag)))
names(t.lodes.temp)[3] <- "NUM"
names(t.lodes.temp)[4] <- "QUER"
f.message(type = "MESSAGE", message = paste0("Calculating 'D_IN_T'. Estimated time remaining: ", ifelse((nrow(t.lodes) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 4/10)
t.units$D_IN_T <- mapply(function(geoid) {
i <- which(t.lodes.temp$WORK == geoid)
weights <- t.lodes.temp$NUM[i]
distances <- t.lodes.temp$QUER[i]
sum(distances * weights, na.rm = TRUE) / sum(weights, na.rm = TRUE)
}, s.units$GEOID)
f.message(type = "MESSAGE", message = paste0("Calculating 'D_OUT_T'. Estimated time remaining: ", ifelse((nrow(t.lodes) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 5/10)
t.units$D_OUT_T <- mapply(function(geoid) {
i <- which(t.lodes.temp$HOME == geoid)
weights <- t.lodes.temp$NUM[i]
distances <- t.lodes.temp$QUER[i]
sum(distances * weights, na.rm = TRUE) / sum(weights, na.rm = TRUE)
}, s.units$GEOID)
f.message(type = "MESSAGE", message = paste0("Calculating 'T_IN_T'. Estimated time remaining: ", ifelse((nrow(t.lodes) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 4/10)
t.units$T_IN_T <- mapply(function(geoid) {
if (geoid %in% t.lodes.temp$WORK) {
sum(t.lodes.temp$NUM[t.lodes.temp$WORK == geoid], na.rm = TRUE)
} else {
NA
}
}, t.units$GEOID)
f.message(type = "MESSAGE", message = paste0("Calculating 'T_OUT_T'. Estimated time remaining: ", ifelse((nrow(t.lodes) / 1000000) * 25 < 60, paste0(round((nrow(t.lodes) / 1000000) * 25, 0), " seconds."), paste0(round((nrow(t.lodes) / 60000000) * 25, 1), " minutes."))), write = FALSE, adjustment = 5/10)
t.units$T_OUT_T <- mapply(function(geoid) {
if (geoid %in% t.lodes.temp$HOME) {
sum(t.lodes.temp$NUM[t.lodes.temp$HOME == geoid], na.rm = TRUE)
} else {
NA
}
}, t.units$GEOID)
# UPDATE: Clean this up to avoid creating t.lodes.temp
if (nrow(t.units) > 100) {
f.message(type = "MESSAGE", message = "Culling potential outliers.", write = FALSE, adjustment = 9/10)
t.count <- nrow(t.units)
t.in.min <- median(t.units$D_IN, na.rm = TRUE) - 4 * sd(t.units$D_IN, na.rm = TRUE)
t.out.min <- median(t.units$D_OUT, na.rm = TRUE) - 4 * sd(t.units$D_OUT, na.rm = TRUE)
t.in.max <- median(t.units$D_IN, na.rm = TRUE) + 4 * sd(t.units$D_IN, na.rm = TRUE)
t.out.max <- median(t.units$D_OUT, na.rm = TRUE) + 4 * sd(t.units$D_OUT, na.rm = TRUE)
t.units$D_IN[(t.units$D_IN < t.in.min |t.units$D_IN > t.in.max)] <- NA
t.units$D_OUT[(t.units$D_OUT < t.out.min |t.units$D_OUT > t.out.max)] <- NA
f.message(type = "MESSAGE", message = paste0("Culled ", nrow(t.units) - t.count, " potential outliers."), write = TRUE, adjustment = 9/10)
rm(t.in.min, t.out.min, t.in.max, t.out.max)
}
t.units$D_IN[t.units$T_IN < h.minusers] <- NA
t.units$D_OUT[t.units$T_OUT < h.minusers] <- NA
f.message(type = "MESSAGE", message = paste0("Writing outputs to: ", p.resultssite), write = TRUE, adjustment = 10/10)
f.message(type = "MESSAGE", message = paste0("Writing to aggregate-scale output table in: ", p.resultssite), write = FALSE, adjustment = 10/10)
t.aggregateprofile$D_IN[t.aggregateprofile$YEAR == i.year] <- sum(t.units$D_IN * t.units$T_IN, na.rm = TRUE) / sum(t.units$T_IN, na.rm = TRUE)
t.aggregateprofile$D_OUT[t.aggregateprofile$YEAR == i.year] <- sum(t.units$D_OUT * t.units$T_OUT, na.rm = TRUE) / sum(t.units$T_OUT, na.rm = TRUE)
t.aggregateprofile$D_SELF[t.aggregateprofile$YEAR == i.year] <- sum(t.lodes.incl$NUM * t.lodes.incl$QUER, na.rm = TRUE) / sum(t.lodes.incl$NUM, na.rm = TRUE)
t.aggregateprofile$AREA_KM2[t.aggregateprofile$YEAR == i.year] <- as.double(st_area(s.agg)) / 1000000
t.aggregateprofile$T_IN[t.aggregateprofile$YEAR == i.year] <- sum(t.units$T_IN, na.rm = TRUE)
t.aggregateprofile$T_OUT[t.aggregateprofile$YEAR == i.year] <- sum(t.units$T_OUT, na.rm = TRUE)
t.aggregateprofile$T_SELF[t.aggregateprofile$YEAR == i.year] <- sum(t.lodes.incl$NUM, na.rm = TRUE)
t.aggregateprofile$P_IN[t.aggregateprofile$YEAR == i.year] <- sum(t.units$T_IN, na.rm = TRUE) / (sum(t.units$T_IN, na.rm = TRUE) + sum(t.lodes.incl$NUM, na.rm = TRUE))
t.aggregateprofile$P_OUT[t.aggregateprofile$YEAR == i.year] <- sum(t.units$T_OUT, na.rm = TRUE) / (sum(t.units$T_OUT, na.rm = TRUE) + sum(t.lodes.incl$NUM, na.rm = TRUE))
t.aggregateprofile$D_IN_T[t.aggregateprofile$YEAR == i.year] <- sum(t.units$D_IN_T * t.units$T_IN_T, na.rm = TRUE) / sum(t.units$T_IN_T, na.rm = TRUE)
t.aggregateprofile$D_OUT_T[t.aggregateprofile$YEAR == i.year] <- sum(t.units$D_OUT_T * t.units$T_OUT_T, na.rm = TRUE) / sum(t.units$T_OUT_T, na.rm = TRUE)
toc(log = TRUE)
t.aggregateprofile$RUNTIME[t.aggregateprofile$YEAR == i.year] <- gsub(" sec elapsed", "", tic.log())
tic.clearlog()
write.csv(t.aggregateprofile, file.path(p.resultssite, i.segment, list.files(file.path(p.resultssite, i.segment))[grepl("Aggregate Profile", list.files(file.path(p.resultssite, i.segment)))]), row.names = FALSE)
t.osrmargs <- ifelse(sum(grepl("Network Distance", i.segment)) == 1, "(km)", ifelse (sum(grepl("Network Time", i.segment)) == 1, "(min)", "(km)"))
if (sum(grepl("Network Distance", i.segment)) == 1) {
t.maxdistance <- predict(m.dist, newdata = data.frame(D_KM = h.maxdistance, D_KM_SQRT = sqrt(h.maxdistance)))
t.plotmax <- ceiling(predict(m.dist, newdata = data.frame(D_KM = h.plotmax, D_KM_SQRT = sqrt(h.plotmax))) / 10) * 10
} else if (sum(grepl("Network Time", i.segment)) == 1) {
t.maxdistance <- predict(m.time, newdata = data.frame(D_KM = h.maxdistance, D_KM_SQRT = sqrt(h.maxdistance)))
t.plotmax <- ceiling(predict(m.dist, newdata = data.frame(D_KM = h.plotmax, D_KM_SQRT = sqrt(h.plotmax))) / 10) * 10
} else {
t.maxdistance <- h.maxdistance
t.plotmax <- h.plotmax
}
f.message(type = "MESSAGE", message = paste0("Writing unit-scale EED map to: ", p.resultssite), write = FALSE, adjustment = 10/10)
i.plot <- "D_IN" # Debugging
for (i.plot in c("D_IN", "D_OUT", "D_SELF_IN", "D_SELF_OUT", "D_IN_T", "D_OUT_T")) {
if (grepl("SELF", i.plot) == TRUE) {
if (f.levelfromalias(a.agg) <= f.levelfromalias("State")) {
t.plotmax.temp <- ceiling(max(t.units$D_SELF_IN, t.units$D_SELF_OUT, na.rm = TRUE) / 10) * 10
} else {
t.plotmax.temp <- ceiling(sqrt((as.double(st_area(s.agg))/1000000)/3.14) * 0.2) * 10
}
} else {
if (i.plot == "D_IN_T" | i.plot == "D_OUT_T") {
if (max(t.units$D_IN, t.units$D_OUT, na.rm = TRUE) > t.plotmax) {
if (f.levelfromalias(a.agg) %in% f.levelfromalias(c("CBSA", "CSA", "MSA")) | f.levelfromalias(a.agg) <= f.levelfromalias("State")) {
t.plotmax.temp <- ceiling(round(max(t.units$D_IN, t.units$D_OUT, na.rm = TRUE), 0) / (10 ^ (nchar(round(max(t.units$D_IN, t.units$D_OUT, na.rm = TRUE), 0)) - 1))) * (10 ^ (nchar(round(max(t.units$D_IN, t.units$D_OUT, na.rm = TRUE), 0)) - 1)) / 1.5
} else {
t.plotmax.temp <- round(h.plotmax * 1.5 / 15) * 10
}
} else {
t.plotmax.temp <- ceiling(t.plotmax / 20) * 10
}
} else {
if (max(t.units$D_IN, t.units$D_OUT, na.rm = TRUE) > t.plotmax) {
if (f.levelfromalias(a.agg) %in% f.levelfromalias(c("CBSA", "CSA", "MSA")) | f.levelfromalias(a.agg) <= f.levelfromalias("State")) {
t.plotmax.temp <- ceiling(round(max(t.units$D_IN, t.units$D_OUT, na.rm = TRUE), 0) / (10 ^ (nchar(round(max(t.units$D_IN, t.units$D_OUT, na.rm = TRUE), 0)) - 1))) * (10 ^ (nchar(round(max(t.units$D_IN, t.units$D_OUT, na.rm = TRUE), 0)) - 1))
} else {
t.plotmax.temp <- round(h.plotmax * 1.5 / 10) * 10
}
} else {
t.plotmax.temp <- t.plotmax
}
}
}
t.plot <- ggplot() +
geom_sf(data = t.units, aes(fill = .data[[i.plot]]), color = NA) +
scale_fill_gradient(low = "white",
high = h.accent.1,
limits = c(0, t.plotmax.temp)) +
geom_sf(data = t.units, fill = NA, color = alpha("white", 0.25), size = 0.01) +
geom_sf(data = s.agg, fill = NA, color = "black", size = 2, linetype = "dashed") +
theme(
plot.title    = element_text(hjust = 0.5, face = "bold", size = 12),
plot.subtitle = element_text(hjust = 0.5, face = "italic", size = 10),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.x = element_blank(),
axis.ticks.y = element_blank()
) +
labs(
title = ifelse(i.plot == "D_IN", "Mean Labor Import Distance",
ifelse(i.plot == "D_OUT", "Mean Labor Export Distance",
ifelse(i.plot == "D_SELF_IN", "Mean Labor Import Distance",
ifelse(i.plot == "D_IN_T", "Mean Labor Import Distance (Total)",
ifelse(i.plot == "D_OUT_T", "Mean Labor Export Distance (Total)", "Mean Labor Export Distance"))))),
subtitle = ifelse(i.plot == "D_IN", "Non-Local (EED In)",
ifelse(i.plot == "D_OUT", "Non-Local (EED Out)",
ifelse(i.plot == "D_SELF_IN", "Local (EED Self In)",
ifelse(i.plot == "D_IN_T", "Non-Local (EED In, Total)",
ifelse(i.plot == "D_OUT_T", "Non-Local (EED Out, Total)", "Local (EED Self Out)")))))
) +
guides(fill=guide_legend(title = paste0(ifelse(i.plot == "D_IN", "EED In",
ifelse(i.plot == "D_OUT", "EED Out",
ifelse(i.plot == "D_SELF_IN", "EED In",
ifelse(i.plot == "D_IN_T", "EED In (Total)",
ifelse(i.plot == "D_OUT_T", "EED Out (Total)", "EED Out"))))), " ", t.osrmargs)))
f.message(type = "MESSAGE", message = paste0("Writing unit-scale EED histogram to: ", p.resultssite), write = FALSE, adjustment = 10/10)
t.plot2 <- ggplot() +
geom_histogram(data = t.units, aes(x = !!sym(i.plot)), binwidth = 1, color = NA, fill = "lightgray") +
geom_vline(xintercept = mean(unlist(st_drop_geometry(t.units[, i.plot])), na.rm = TRUE),
color  = h.accent.1, linetype = "dashed", linewidth = 1) +
annotate("text",
x = mean(unlist(st_drop_geometry(t.units[, i.plot])), na.rm = TRUE),
y = 20,
label = paste0("Mean: ", round(mean(unlist(st_drop_geometry(t.units[, i.plot])), na.rm = TRUE), 2), " km"),
color = alpha(h.accent.1, 0.5), angle = 90, vjust = -0.5, fontface = "bold") +
theme(
plot.title    = element_text(hjust = 0.5, face = "bold", size = 12),
plot.subtitle = element_text(hjust = 0.5, face = "italic", size = 10),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank()
) +
xlim(c(0, ceiling(max(t.units$D_IN, t.units$D_OUT, t.units$D_SELF_IN, t.units$D_SELF_OUT, na.rm = TRUE) / 10) * 10)) +
ylab("Count") +
xlab(ifelse(i.plot == "D_IN", "Mean Labor Import Distance (Non-Local EED In)",
ifelse(i.plot == "D_OUT", "Mean Labor Export Distance (Non-Local EED Out)",
ifelse(i.plot == "D_SELF_IN", "Mean Labor Import Distance (Local EED In)",
ifelse(i.plot == "D_IN_T", "Mean Labor Import Distance (Non-Local EED In, Total)",
ifelse(i.plot == "D_OUT_T", "Mean Labor Export Distance (Non-Local EED Out, Total)", "Mean Labor Export Distance (Local EED Out)"))))))
assign(paste0("t.plot.", i.plot), t.plot)
assign(paste0("t.plot2.", i.plot), t.plot2)
rm(t.plot, t.plot2, i.plot)
}
rm(t.osrmargs, t.plotmax.temp)
t.plot <- (t.plot.D_IN + t.plot.D_OUT + t.plot.D_SELF_IN + t.plot.D_SELF_OUT + t.plot.D_IN_T + t.plot.D_OUT_T + plot_layout(ncol = 2)) + # UPDATE: below line if level smaller than state
plot_annotation(title = paste0(i.sitename, ", ", o.sites$STATE[i.site], ", ", i.year),
subtitle = paste0("Segment '", i.segment, "'"),
theme = theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
plot.subtitle = element_text(hjust = 0.5, size = 14, face = "italic")))
t.plot2 <- (t.plot2.D_IN + t.plot2.D_OUT + t.plot2.D_SELF_IN + t.plot2.D_SELF_OUT + t.plot2.D_IN_T + t.plot2.D_OUT_T + plot_layout(ncol = 1)) + # UPDATE: below line if level smaller than state
plot_annotation(title = paste0(i.sitename, ", ", o.sites$STATE[i.site], ", ", i.year),
subtitle = paste0("Segment '", i.segment, "'"),
theme = theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
plot.subtitle = element_text(hjust = 0.5, size = 14, face = "italic")))
suppressWarnings(ggsave(file.path(p.resultssite, i.segment, paste0("Unit Map - ", o.sites$STATE[i.site], " - ", toupper(i.sitename), " - ", i.segment, " - ", i.year, ".", h.device)), plot = t.plot, device = h.device, units = "px", height = 4000, width = 4000))
suppressWarnings(ggsave(file.path(p.resultssite, i.segment, paste0("Unit Histogram - ", o.sites$STATE[i.site], " - ", toupper(i.sitename), " - ", i.segment, " - ", i.year, ".", h.device)), plot = t.plot2, device = h.device, units = "px", height = 6000, width = 3000))
rm(list = ls(pattern = "t.plot"))
rm(list = ls(pattern = "t.plot2"))
rm(t.lodes.temp)
# Append data to Unit Profile
f.message(type = "MESSAGE", message = paste0("Writing to unit-scale output table in: ", p.resultssite), write = FALSE, adjustment = 10/10)
t.units <- st_drop_geometry(t.units)
t.units <- t.units %>% select(-T_IN, -T_OUT, -T_IN_T, -T_OUT_T)
names(t.units)[!names(t.units) %in% "GEOID"] <- paste0(names(t.units)[!names(t.units) %in% "GEOID"], "_", i.year)
t.unitprofile <- t.unitprofile %>% select(-any_of(names(t.units)[!names(t.units) %in% "GEOID"]))
t.unitprofile <- merge(t.unitprofile, t.units, by = "GEOID", all.x = TRUE, all.y = TRUE)
t.unitprofile <- t.unitprofile[, c(1, order(colnames(t.unitprofile[!names(t.unitprofile) %in% "GEOID"]))+1)]
t.unitprofile <- t.unitprofile[order(t.unitprofile$GEOID), ]
write.csv(t.unitprofile, file.path(p.resultssite, i.segment, list.files(file.path(p.resultssite, i.segment))[grepl("Unit Profile", list.files(file.path(p.resultssite, i.segment)))]), row.names = FALSE)
rm(t.unitprofile, t.units)
# Create distance histogram
f.message(type = "MESSAGE", message = paste0("Writing aggregate-scale EED histogram to: ", p.resultssite), write = FALSE, adjustment = 10/10)
t.freq.self <- data.frame(QUER = rep(t.lodes.incl$QUER, times = t.lodes.incl$NUM))
t.freq.self$GROUP <- "SELF"
t.freq.in <- data.frame(QUER = rep(t.lodes.excl$QUER[t.lodes.excl$WORK %in% s.units$GEOID], times = t.lodes.excl$NUM[t.lodes.excl$WORK %in% s.units$GEOID]))
t.freq.in$GROUP <- "IN"
if (nrow(t.freq.in) == 0) {
t.freq.in <- data.frame(QUER = 0, GROUP = "IN")
t.freq.in(type = "WARNING", code = "W-00027", message = "No in-bound routes detected. Adding a single 0km distance route for visualization.")
} else {
t.freq.in$GROUP <- "IN"
}
t.freq.out <- data.frame(QUER = rep(t.lodes.excl$QUER[t.lodes.excl$HOME %in% s.units$GEOID], times = t.lodes.excl$NUM[t.lodes.excl$HOME %in% s.units$GEOID]))
if (nrow(t.freq.out) == 0) {
t.freq.out <- data.frame(QUER = 0, GROUP = "OUT")
f.message(type = "WARNING", code = "W-00027", message = "No out-bound routes detected. Adding a single 0km distance route for visualization.")
} else {
t.freq.out$GROUP <- "OUT"
}
t.freq <- rbind(t.freq.self, t.freq.in, t.freq.out)
rm(t.freq.in, t.freq.out, t.freq.self)
if (sum(t.freq$GROUP == "SELF") == 0) {
t.freq[nrow(t.freq) + 1, ] <- c(0, "SELF")
}
if (sum(grepl("Network Distance", i.segment)) == 1) {
t.maxdistance <- predict(m.dist, newdata = data.frame(D_KM = h.maxdistance, D_KM_SQRT = sqrt(h.maxdistance)))
t.maxdistance <- ceiling(t.maxdistance / 10) * 10
t.breaks <- seq(0, t.maxdistance / 10)
t.hist <- data.frame(BAND = paste0(t.breaks[1:length(t.breaks) - 1] * 10, "-", t.breaks[2:length(t.breaks)] * 10))
} else if (sum(grepl("Network Time", i.segment)) == 1) {
t.maxdistance <- predict(m.time, newdata = data.frame(D_KM = h.maxdistance, D_KM_SQRT = sqrt(h.maxdistance)))
t.maxdistance <- ceiling(t.maxdistance / 10) * 10
t.breaks <- seq(0, t.maxdistance / 10)
t.hist <- data.frame(BAND = paste0(t.breaks[1:length(t.breaks) - 1] * 10, "-", t.breaks[2:length(t.breaks)] * 10))
} else {
t.maxdistance <- h.maxdistance
t.breaks <- seq(0, h.maxdistance / 10)
t.hist <- data.frame(BAND = paste0(t.breaks[1:length(t.breaks) - 1] * 10, "-", t.breaks[2:length(t.breaks)] * 10))
}
i.band <- 0 # Debugging
for (i.band in 0:(nrow(t.hist)-1)) {
t.hist[(i.band + 1), "T_SELF"] <- sum(t.freq$GROUP == "SELF" & t.freq$QUER >= i.band * 10 & t.freq$QUER < (i.band + 1) * 10)
t.hist[(i.band + 1), "T_IN"] <- sum(t.freq$GROUP == "IN" & t.freq$QUER >= i.band * 10 & t.freq$QUER < (i.band + 1) * 10)
t.hist[(i.band + 1), "T_OUT"] <- sum(t.freq$GROUP == "OUT" & t.freq$QUER >= i.band * 10 & t.freq$QUER < (i.band + 1) * 10)
t.hist[(i.band + 1), "RPERC_SELF"] <- t.hist[(i.band + 1), "T_SELF"] / sum(t.freq$GROUP == "SELF")
t.hist[(i.band + 1), "RPERC_IN"] <- t.hist[(i.band + 1), "T_IN"] / sum(t.freq$GROUP == "IN")
t.hist[(i.band + 1), "RPERC_OUT"] <- t.hist[(i.band + 1), "T_OUT"] / sum(t.freq$GROUP == "OUT")
t.hist[(i.band + 1), "CPERC_SELF"] <- sum(t.hist[1:(i.band + 1), "T_SELF"]) / sum(t.freq$GROUP == "SELF")
t.hist[(i.band + 1), "CPERC_IN"] <- sum(t.hist[1:(i.band + 1), "T_IN"]) / sum(t.freq$GROUP == "IN")
t.hist[(i.band + 1), "CPERC_OUT"] <- sum(t.hist[1:(i.band + 1), "T_OUT"]) / sum(t.freq$GROUP == "OUT")
rm(i.band)
}
if (sum(grepl("Network Time", i.segment)) == 1) {
t.hist$RADIUS_KM <- predict(m.time, newdata = data.frame(D_KM = sqrt((as.double(st_area(s.agg))/1000000)/3.14),
D_KM_SQRT = sqrt((as.double(st_area(s.agg))/1000000)/3.14)))
} else {
t.hist$RADIUS_KM <- sqrt((as.double(st_area(s.agg))/1000000)/3.14)
}
t.plot <- ggplot(t.freq, aes(x = QUER, fill = GROUP)) +
geom_histogram(aes(y = after_stat(count / sum(count))), position = "stack", bins = 25) +
labs(x = ifelse(sum(grepl("Network Distance", i.segment)) == 1, "Network Distance (km)", ifelse (sum(grepl("Network Time", i.segment)) == 1, "Network Time (min)", "Geodesic Distance (km)")), y = "Relative Frequency", title = paste0(ifelse(nchar(i.sitename) > 15, paste0(substr(i.sitename, 0, 15), "..."), i.sitename), ", Year ", i.year, ", ", i.segment)) +
geom_vline(xintercept = sqrt((as.double(st_area(s.agg))/1000000)/3.14), color = alpha("black", 0.5), linetype = "dashed", linewidth = 0.5) +
geom_vline(xintercept = t.aggregateprofile$D_IN[t.aggregateprofile$YEAR == i.year], color = alpha(h.accent.2, 0.5), linetype = "dashed", linewidth = 0.5) +
geom_vline(xintercept = t.aggregateprofile$D_OUT[t.aggregateprofile$YEAR == i.year], color = alpha(h.accent.3, 0.5), linetype = "dashed", linewidth = 0.5) +
annotate("text", x = sqrt((as.double(st_area(s.agg))/1000000)/3.14), y = 0.2, label = paste0(ifelse(sum(grepl("Network Time", i.segment)) == 1, "Approx. Site Radius (min): ", "Approx. Site Radius (km): "), round(t.hist$RADIUS_KM[1], digits = 2)), color = alpha("black", 0.5), angle = 90, vjust = -0.5) +
annotate("text", x = t.aggregateprofile$D_IN[t.aggregateprofile$YEAR == i.year], y = 0.2, label = paste0(ifelse(sum(grepl("Network Time", i.segment)) == 1, "Mean EED In (min): ", "Mean EED In (km): "), round(t.aggregateprofile$D_IN[t.aggregateprofile$YEAR == i.year], digits = 2)), color = alpha(h.accent.2, 0.5), angle = 90, vjust = -0.5) +
annotate("text", x = t.aggregateprofile$D_OUT[t.aggregateprofile$YEAR == i.year], y = 0.2, label = paste0(ifelse(sum(grepl("Network Time", i.segment)) == 1, "Mean EED Out (min): ", "Mean EED Out (km): "), round(t.aggregateprofile$D_OUT[t.aggregateprofile$YEAR == i.year], digits = 2)), color = alpha(h.accent.3, 0.5), angle = 90, vjust = -0.5) +
ylim(c(0, 0.3)) +
xlim(c(0,t.maxdistance)) +
theme_minimal()
suppressWarnings(ggsave(file.path(p.resultssite, i.segment, paste0("Aggregate Histogram - ", o.sites$STATE[i.site], " - ", toupper(i.sitename), " - ", i.segment, " - ", i.year, ".", h.device)), plot = t.plot, device = h.device, units = "px", height = 2000, width = 2000))
write.csv(t.hist, file = file.path(p.resultssite, i.segment, paste0("Aggregate Histogram Data - ", o.sites$STATE[i.site], " - ", toupper(i.sitename), " - ", i.segment, " - ", i.year, ".csv")), row.names = FALSE)
rm(i.segment, t.aggregateprofile, t.plot, t.hist, t.freq, t.lodes.excl, t.lodes.incl, i.segment.clean, i.segment.tag)
}
rm(i.site, p.resultssite)
}
rm(i.year)
if (exists("t.lodes")) {rm(t.lodes)}
}
f.message(type = "MESSAGE", message = "SUCCESS! All processess complete.", write = TRUE)
cat("\014")
cat(format(Sys.time(), "%X"), " | ", bold(green("MESSAGE: ")), bold(red("S")), bold(yellow("U")), bold(green("C")), bold(blue("C")), bold(magenta("E")), bold(red("S")), bold(yellow("S")), bold(green("!")), " Site processing complete.\n", sep = "")
test <- data.frame(NUMBERS = 1:10)
write.csv(test, file.path("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt", "Test.csv"), row.names = FALSE)
write.csv(test, file.path(r"C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt", "Test.csv"), row.names = FALSE)
write.csv(test, file.path(r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt", "Test.csv)"), row.names = FALSE)
write.csv(test, file.path(r("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt"), "Test.csv"), row.names = FALSE)
write.csv(test, file.path(r("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)", "Test.csv"), row.names = FALSE)
r("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt")
r("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt")
r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)", "Test.csv")
r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)"
file.path(r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)", "Test.csv")
write.csv(test, file.path(r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)", "Test.csv"), row.names = FALSE)
library(Rfast)
argument = "10:20"
t.arg1 <- sub("\\:.*", "", argument)
t.arg2 <- sub(".*:", "", my_string)
t.arg2 <- sub(".*:", "", argument)
t.arg1 <- as.numeric(sub("\\:.*", "", argument))
t.arg2 <- as.numeric(sub(".*:", "", argument))
t.arg1:t.arg2
argument = "Total Population"
sum(grepl(" ", argument)) > 0 | sum(grepl(",", argument)) == 0 & allowspaces == FALSE
allowspaces = TRUE
sum(grepl(" ", argument)) > 0 | sum(grepl(",", argument)) == 0 & allowspaces == FALSE
allowspaces
sum(grepl(" ", argument)) > 0
allowspaces
allowspaces == FALSE
sum(grepl(" ", argument)) > 0 | sum(grepl(",", argument)) == 0 & allowspaces == FALSE
(sum(grepl(" ", argument)) > 0 | sum(grepl(",", argument)) == 0) & allowspaces == FALSE
h.tempdir = "USMTEMP"
!file.exists(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir))
h.tempmax = 1000000
file.path(Sys.getenv("LOCALAPPDATA"), "Temp")
list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp"))
!h.tempdir %in% (file.path(Sys.getenv("LOCALAPPDATA"), "Temp"))
!h.tempdir %in% list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp"))
file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir)
file.size(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir))
list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir))
sum(sapply(list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir), full.names = TRUE), file.size))
sum(sapply(list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir), full.names = TRUE), file.size)) > h.tempmax
f.message(type = "MESSAGE", message = paste0("Temp directory exceeds local limit of ", ifelse(h.tempmax < 1000, paste0(h.tempmax, " bytes"),
ifelse(h.tempmax < 1000000, paste0(h.tempmax / 1000, " kB"),
ifelse(h.tempmax < 1000000000, paste0(h.tempmax / 1000000, " MB"), paste0(h.tempmax / 1000000000, " Gb")))), ". Dumping temp files."), write = TRUE)
list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir), full.names = TRUE)
t.delete <- list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir), full.names = TRUE)
unlink(t.delete, force = TRUE)
rm(t.delete)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
devtools::install_github("plasc2/nucleus", force = TRUE)
devtools::install_github("plasc2/nucleus", force = TRUE)
library(nucleus)
devtools::uninstall("nucleus")
devtools::uninstall(nucleus)
remove.packages(nucleus)
remove.packages("nucleus")
devtools::install_github("plasc2/nucleus")
devtools::install_github("plasc2/nucleus")
library(nucleus)
visualize_site()
setwd("C:/Users/jremigio/OneDrive/Doctoral Studies/02 - Projects/25F-1 - Nucleus/Code/nucleus")
devtools::check()
?alpha
devtools::check()
devtools::check()
importFrom("utils", "getFromNamespace")
devtools::install_github("plasc2/nucleus", force= TRUE)
library(nucleus)
visualize_site("Parker county, texas", output_directory = r"(C:\Users\jremigio\OneDrive\Doctoral Studies\02 - Projects\25F-1 - Nucleus\Code\nucleus)")
