ifelse(i.plot == "D_IN_T", "Mean Labor Import Distance (Non-Local EED In, Total)",
ifelse(i.plot == "D_OUT_T", "Mean Labor Export Distance (Non-Local EED Out, Total)", "Mean Labor Export Distance (Local EED Out)"))))))
assign(paste0("t.plot.", i.plot), t.plot)
assign(paste0("t.plot2.", i.plot), t.plot2)
rm(t.plot, t.plot2, i.plot)
}
rm(t.osrmargs, t.plotmax.temp)
t.plot <- (t.plot.D_IN + t.plot.D_OUT + t.plot.D_SELF_IN + t.plot.D_SELF_OUT + t.plot.D_IN_T + t.plot.D_OUT_T + plot_layout(ncol = 2)) + # UPDATE: below line if level smaller than state
plot_annotation(title = paste0(i.sitename, ", ", o.sites$STATE[i.site], ", ", i.year),
subtitle = paste0("Segment '", i.segment, "'"),
theme = theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
plot.subtitle = element_text(hjust = 0.5, size = 14, face = "italic")))
t.plot2 <- (t.plot2.D_IN + t.plot2.D_OUT + t.plot2.D_SELF_IN + t.plot2.D_SELF_OUT + t.plot2.D_IN_T + t.plot2.D_OUT_T + plot_layout(ncol = 1)) + # UPDATE: below line if level smaller than state
plot_annotation(title = paste0(i.sitename, ", ", o.sites$STATE[i.site], ", ", i.year),
subtitle = paste0("Segment '", i.segment, "'"),
theme = theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
plot.subtitle = element_text(hjust = 0.5, size = 14, face = "italic")))
suppressWarnings(ggsave(file.path(p.resultssite, i.segment, paste0("Unit Map - ", o.sites$STATE[i.site], " - ", toupper(i.sitename), " - ", i.segment, " - ", i.year, ".", h.device)), plot = t.plot, device = h.device, units = "px", height = 4000, width = 4000))
suppressWarnings(ggsave(file.path(p.resultssite, i.segment, paste0("Unit Histogram - ", o.sites$STATE[i.site], " - ", toupper(i.sitename), " - ", i.segment, " - ", i.year, ".", h.device)), plot = t.plot2, device = h.device, units = "px", height = 6000, width = 3000))
rm(list = ls(pattern = "t.plot"))
rm(list = ls(pattern = "t.plot2"))
rm(t.lodes.temp)
# Append data to Unit Profile
f.message(type = "MESSAGE", message = paste0("Writing to unit-scale output table in: ", p.resultssite), write = FALSE, adjustment = 10/10)
t.units <- st_drop_geometry(t.units)
t.units <- t.units %>% select(-T_IN, -T_OUT, -T_IN_T, -T_OUT_T)
names(t.units)[!names(t.units) %in% "GEOID"] <- paste0(names(t.units)[!names(t.units) %in% "GEOID"], "_", i.year)
t.unitprofile <- t.unitprofile %>% select(-any_of(names(t.units)[!names(t.units) %in% "GEOID"]))
t.unitprofile <- merge(t.unitprofile, t.units, by = "GEOID", all.x = TRUE, all.y = TRUE)
t.unitprofile <- t.unitprofile[, c(1, order(colnames(t.unitprofile[!names(t.unitprofile) %in% "GEOID"]))+1)]
t.unitprofile <- t.unitprofile[order(t.unitprofile$GEOID), ]
write.csv(t.unitprofile, file.path(p.resultssite, i.segment, list.files(file.path(p.resultssite, i.segment))[grepl("Unit Profile", list.files(file.path(p.resultssite, i.segment)))]), row.names = FALSE)
rm(t.unitprofile, t.units)
# Create distance histogram
f.message(type = "MESSAGE", message = paste0("Writing aggregate-scale EED histogram to: ", p.resultssite), write = FALSE, adjustment = 10/10)
t.freq.self <- data.frame(QUER = rep(t.lodes.incl$QUER, times = t.lodes.incl$NUM))
t.freq.self$GROUP <- "SELF"
t.freq.in <- data.frame(QUER = rep(t.lodes.excl$QUER[t.lodes.excl$WORK %in% s.units$GEOID], times = t.lodes.excl$NUM[t.lodes.excl$WORK %in% s.units$GEOID]))
t.freq.in$GROUP <- "IN"
if (nrow(t.freq.in) == 0) {
t.freq.in <- data.frame(QUER = 0, GROUP = "IN")
t.freq.in(type = "WARNING", code = "W-00027", message = "No in-bound routes detected. Adding a single 0km distance route for visualization.")
} else {
t.freq.in$GROUP <- "IN"
}
t.freq.out <- data.frame(QUER = rep(t.lodes.excl$QUER[t.lodes.excl$HOME %in% s.units$GEOID], times = t.lodes.excl$NUM[t.lodes.excl$HOME %in% s.units$GEOID]))
if (nrow(t.freq.out) == 0) {
t.freq.out <- data.frame(QUER = 0, GROUP = "OUT")
f.message(type = "WARNING", code = "W-00027", message = "No out-bound routes detected. Adding a single 0km distance route for visualization.")
} else {
t.freq.out$GROUP <- "OUT"
}
t.freq <- rbind(t.freq.self, t.freq.in, t.freq.out)
rm(t.freq.in, t.freq.out, t.freq.self)
if (sum(t.freq$GROUP == "SELF") == 0) {
t.freq[nrow(t.freq) + 1, ] <- c(0, "SELF")
}
if (sum(grepl("Network Distance", i.segment)) == 1) {
t.maxdistance <- predict(m.dist, newdata = data.frame(D_KM = h.maxdistance, D_KM_SQRT = sqrt(h.maxdistance)))
t.maxdistance <- ceiling(t.maxdistance / 10) * 10
t.breaks <- seq(0, t.maxdistance / 10)
t.hist <- data.frame(BAND = paste0(t.breaks[1:length(t.breaks) - 1] * 10, "-", t.breaks[2:length(t.breaks)] * 10))
} else if (sum(grepl("Network Time", i.segment)) == 1) {
t.maxdistance <- predict(m.time, newdata = data.frame(D_KM = h.maxdistance, D_KM_SQRT = sqrt(h.maxdistance)))
t.maxdistance <- ceiling(t.maxdistance / 10) * 10
t.breaks <- seq(0, t.maxdistance / 10)
t.hist <- data.frame(BAND = paste0(t.breaks[1:length(t.breaks) - 1] * 10, "-", t.breaks[2:length(t.breaks)] * 10))
} else {
t.maxdistance <- h.maxdistance
t.breaks <- seq(0, h.maxdistance / 10)
t.hist <- data.frame(BAND = paste0(t.breaks[1:length(t.breaks) - 1] * 10, "-", t.breaks[2:length(t.breaks)] * 10))
}
i.band <- 0 # Debugging
for (i.band in 0:(nrow(t.hist)-1)) {
t.hist[(i.band + 1), "T_SELF"] <- sum(t.freq$GROUP == "SELF" & t.freq$QUER >= i.band * 10 & t.freq$QUER < (i.band + 1) * 10)
t.hist[(i.band + 1), "T_IN"] <- sum(t.freq$GROUP == "IN" & t.freq$QUER >= i.band * 10 & t.freq$QUER < (i.band + 1) * 10)
t.hist[(i.band + 1), "T_OUT"] <- sum(t.freq$GROUP == "OUT" & t.freq$QUER >= i.band * 10 & t.freq$QUER < (i.band + 1) * 10)
t.hist[(i.band + 1), "RPERC_SELF"] <- t.hist[(i.band + 1), "T_SELF"] / sum(t.freq$GROUP == "SELF")
t.hist[(i.band + 1), "RPERC_IN"] <- t.hist[(i.band + 1), "T_IN"] / sum(t.freq$GROUP == "IN")
t.hist[(i.band + 1), "RPERC_OUT"] <- t.hist[(i.band + 1), "T_OUT"] / sum(t.freq$GROUP == "OUT")
t.hist[(i.band + 1), "CPERC_SELF"] <- sum(t.hist[1:(i.band + 1), "T_SELF"]) / sum(t.freq$GROUP == "SELF")
t.hist[(i.band + 1), "CPERC_IN"] <- sum(t.hist[1:(i.band + 1), "T_IN"]) / sum(t.freq$GROUP == "IN")
t.hist[(i.band + 1), "CPERC_OUT"] <- sum(t.hist[1:(i.band + 1), "T_OUT"]) / sum(t.freq$GROUP == "OUT")
rm(i.band)
}
if (sum(grepl("Network Time", i.segment)) == 1) {
t.hist$RADIUS_KM <- predict(m.time, newdata = data.frame(D_KM = sqrt((as.double(st_area(s.agg))/1000000)/3.14),
D_KM_SQRT = sqrt((as.double(st_area(s.agg))/1000000)/3.14)))
} else {
t.hist$RADIUS_KM <- sqrt((as.double(st_area(s.agg))/1000000)/3.14)
}
t.plot <- ggplot(t.freq, aes(x = QUER, fill = GROUP)) +
geom_histogram(aes(y = after_stat(count / sum(count))), position = "stack", bins = 25) +
labs(x = ifelse(sum(grepl("Network Distance", i.segment)) == 1, "Network Distance (km)", ifelse (sum(grepl("Network Time", i.segment)) == 1, "Network Time (min)", "Geodesic Distance (km)")), y = "Relative Frequency", title = paste0(ifelse(nchar(i.sitename) > 15, paste0(substr(i.sitename, 0, 15), "..."), i.sitename), ", Year ", i.year, ", ", i.segment)) +
geom_vline(xintercept = sqrt((as.double(st_area(s.agg))/1000000)/3.14), color = alpha("black", 0.5), linetype = "dashed", linewidth = 0.5) +
geom_vline(xintercept = t.aggregateprofile$D_IN[t.aggregateprofile$YEAR == i.year], color = alpha(h.accent.2, 0.5), linetype = "dashed", linewidth = 0.5) +
geom_vline(xintercept = t.aggregateprofile$D_OUT[t.aggregateprofile$YEAR == i.year], color = alpha(h.accent.3, 0.5), linetype = "dashed", linewidth = 0.5) +
annotate("text", x = sqrt((as.double(st_area(s.agg))/1000000)/3.14), y = 0.2, label = paste0(ifelse(sum(grepl("Network Time", i.segment)) == 1, "Approx. Site Radius (min): ", "Approx. Site Radius (km): "), round(t.hist$RADIUS_KM[1], digits = 2)), color = alpha("black", 0.5), angle = 90, vjust = -0.5) +
annotate("text", x = t.aggregateprofile$D_IN[t.aggregateprofile$YEAR == i.year], y = 0.2, label = paste0(ifelse(sum(grepl("Network Time", i.segment)) == 1, "Mean EED In (min): ", "Mean EED In (km): "), round(t.aggregateprofile$D_IN[t.aggregateprofile$YEAR == i.year], digits = 2)), color = alpha(h.accent.2, 0.5), angle = 90, vjust = -0.5) +
annotate("text", x = t.aggregateprofile$D_OUT[t.aggregateprofile$YEAR == i.year], y = 0.2, label = paste0(ifelse(sum(grepl("Network Time", i.segment)) == 1, "Mean EED Out (min): ", "Mean EED Out (km): "), round(t.aggregateprofile$D_OUT[t.aggregateprofile$YEAR == i.year], digits = 2)), color = alpha(h.accent.3, 0.5), angle = 90, vjust = -0.5) +
ylim(c(0, 0.3)) +
xlim(c(0,t.maxdistance)) +
theme_minimal()
suppressWarnings(ggsave(file.path(p.resultssite, i.segment, paste0("Aggregate Histogram - ", o.sites$STATE[i.site], " - ", toupper(i.sitename), " - ", i.segment, " - ", i.year, ".", h.device)), plot = t.plot, device = h.device, units = "px", height = 2000, width = 2000))
write.csv(t.hist, file = file.path(p.resultssite, i.segment, paste0("Aggregate Histogram Data - ", o.sites$STATE[i.site], " - ", toupper(i.sitename), " - ", i.segment, " - ", i.year, ".csv")), row.names = FALSE)
rm(i.segment, t.aggregateprofile, t.plot, t.hist, t.freq, t.lodes.excl, t.lodes.incl, i.segment.clean, i.segment.tag)
}
rm(i.site, p.resultssite)
}
rm(i.year)
if (exists("t.lodes")) {rm(t.lodes)}
}
f.message(type = "MESSAGE", message = "SUCCESS! All processess complete.", write = TRUE)
cat("\014")
cat(format(Sys.time(), "%X"), " | ", bold(green("MESSAGE: ")), bold(red("S")), bold(yellow("U")), bold(green("C")), bold(blue("C")), bold(magenta("E")), bold(red("S")), bold(yellow("S")), bold(green("!")), " Site processing complete.\n", sep = "")
test <- data.frame(NUMBERS = 1:10)
write.csv(test, file.path("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt", "Test.csv"), row.names = FALSE)
write.csv(test, file.path(r"C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt", "Test.csv"), row.names = FALSE)
write.csv(test, file.path(r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt", "Test.csv)"), row.names = FALSE)
write.csv(test, file.path(r("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt"), "Test.csv"), row.names = FALSE)
write.csv(test, file.path(r("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)", "Test.csv"), row.names = FALSE)
r("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt")
r("C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt")
r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)", "Test.csv")
r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)"
file.path(r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)", "Test.csv")
write.csv(test, file.path(r"(C:\Users\jremigio\OneDrive\Cloud Desktop\Sandbox\PyQt)", "Test.csv"), row.names = FALSE)
library(Rfast)
argument = "10:20"
t.arg1 <- sub("\\:.*", "", argument)
t.arg2 <- sub(".*:", "", my_string)
t.arg2 <- sub(".*:", "", argument)
t.arg1 <- as.numeric(sub("\\:.*", "", argument))
t.arg2 <- as.numeric(sub(".*:", "", argument))
t.arg1:t.arg2
argument = "Total Population"
sum(grepl(" ", argument)) > 0 | sum(grepl(",", argument)) == 0 & allowspaces == FALSE
allowspaces = TRUE
sum(grepl(" ", argument)) > 0 | sum(grepl(",", argument)) == 0 & allowspaces == FALSE
allowspaces
sum(grepl(" ", argument)) > 0
allowspaces
allowspaces == FALSE
sum(grepl(" ", argument)) > 0 | sum(grepl(",", argument)) == 0 & allowspaces == FALSE
(sum(grepl(" ", argument)) > 0 | sum(grepl(",", argument)) == 0) & allowspaces == FALSE
h.tempdir = "USMTEMP"
!file.exists(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir))
h.tempmax = 1000000
file.path(Sys.getenv("LOCALAPPDATA"), "Temp")
list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp"))
!h.tempdir %in% (file.path(Sys.getenv("LOCALAPPDATA"), "Temp"))
!h.tempdir %in% list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp"))
file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir)
file.size(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir))
list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir))
sum(sapply(list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir), full.names = TRUE), file.size))
sum(sapply(list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir), full.names = TRUE), file.size)) > h.tempmax
f.message(type = "MESSAGE", message = paste0("Temp directory exceeds local limit of ", ifelse(h.tempmax < 1000, paste0(h.tempmax, " bytes"),
ifelse(h.tempmax < 1000000, paste0(h.tempmax / 1000, " kB"),
ifelse(h.tempmax < 1000000000, paste0(h.tempmax / 1000000, " MB"), paste0(h.tempmax / 1000000000, " Gb")))), ". Dumping temp files."), write = TRUE)
list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir), full.names = TRUE)
t.delete <- list.files(file.path(Sys.getenv("LOCALAPPDATA"), "Temp", h.tempdir), full.names = TRUE)
unlink(t.delete, force = TRUE)
rm(t.delete)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
od_table <- lehdr::grab_lodes(state = "RI", year = 2020, version = "LODES8", lodes_type = "od", job_type = "JT00", segment = "S000", use_cache = TRUE, agg_geo = "tract", state_part = "main")
View(od_table)
units <- tigris::tracts(state = "RI", year = 2020)
View(units)
od_ids %in% names(od_table)
od_ids <- c("h_tract", "w_tract")
od_ids <- c("h_tract", "w_tract")
od_ids %in% names(od_table)
c("test", "w_tract") %in% names(od_table)
!c("test", "w_tract") %in% names(od_table)
("test", "w_tract")[c("test", "w_tract") %in% names(od_table)]
c("test", "w_tract")[c("test", "w_tract") %in% names(od_table)]
od_ids[!od_ids %in% names(od_table)]
od_ids <- c("A", "B")
if (sum(od_ids %in% names(od_table)) != 2) {
stop(paste0("OD ID column name ", od_ids[!od_ids %in% names(od_table)], " not found in OD table."))
}
stop(paste0("OD ID column name ", paste0(od_ids[!od_ids %in% names(od_table)], collapse = " and "), " not found in OD table."))
od_ids <- c("h_tract", "w_tract")
unit_ids <- "GEOID"
stop(paste0("Unit ID column name ", unit_ids, "not found in unit data."))
stop(paste0("Unit ID column name ", unit_ids, " not found in unit data."))
sum(sf::st_drop_geometry(units[, unit_ids]) %in% od_table[od_ids])
View(units)
sf::st_drop_geometry(units[, unit_ids])
View(od_table)
unlist(sf::st_drop_geometry(units[, unit_ids]))
unlist(sf::st_drop_geometry(units[, unit_ids])) %in% od_table[od_ids]
sum(unlist(sf::st_drop_geometry(units[, unit_ids])) %in% od_table[od_ids])
od_table[od_ids]
unlsit(od_table[od_ids])
unlist(od_table[od_ids])
sum(unlist(sf::st_drop_geometry(units[, unit_ids])) %in% unlist(od_table[od_ids]))
c(VALID = TRUE,
MATCHED_UNITS = sum(unlist(sf::st_drop_geometry(units[, unit_ids])) %in% unlist(od_table[od_ids])),
MATCHED_OD = sum(unlist(od_table[od_ids]) %in% unlist(sf::st_drop_geometry(units[, unit_ids]))))
unique(od_table[od_ids[1]])
unique(od_table[od_ids[1]], od_table[od_ids[2]])
unique(unlist(od_table[od_ids[1]]), unlist(od_table[od_ids[2]]))
unique_od_ids <- unique(unlist(od_table[od_ids[1]]), unlist(od_table[od_ids[2]]))
sum(unlist(sf::st_drop_geometry(units[, unit_ids])) %in% unique_od_ids) == 0
sum(unlist(sf::st_drop_geometry(units[, unit_ids])) %in% unique_od_ids)
sum(unlist(sf::st_drop_geometry(units[, unit_ids])) %in% unique_od_ids) / nrow(units)
sum(unique_od_ids %in% unlist(sf::st_drop_geometry(units[, unit_ids])))
sum(unique_od_ids %in% unlist(sf::st_drop_geometry(units[, unit_ids]))) / length(unique_od_ids)
units <- tigris::tracts(state = "RI", year = 2020)
groups <- tigris::states(year = 2020)
groups <- groups[groups$STUSPS == "RI", ]
if (!"sf" %in% class(units) | !"sf" %in% class(groups) {
if (!"sf" %in% class(units) | !"sf" %in% class(groups)) {
stop("Arguments 'units' and 'groups' must be sf.")
}
if (!"sf" %in% class(units)) {
stop("Argument 'units' must be sf.")
}
if (!"sf" %in% class(groups)) {
stop("Argument 'groups' must be sf.")
}
bad <- tigris::tracts(state = "WA", year = 2020)
t.intersection <- sf::st_intersection(groups, units)
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(groups, units))
units$GEOID_A %in% t.intersection$GEOID_A
sum(units$GEOID_A %in% t.intersection$GEOID_A) / nrow(units)
c(VALID = TRUE),
c(VALID = TRUE,
UNITS_IN_GROUPS = sum(units$GEOID_A %in% t.intersection$GEOID_A) / nrow(units),
GROUPS_IN_UNITS = sum(groups$GEOID_B %in% t.intersection$GEOID_B) / nrow(groups))
units <- tigris::tracts(state = "WA", year = 2020)
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(groups, units))
nrow(t.intersection) == 0
units <- tigris::tracts(state = "RI", year = 2020)
sf::st_contains(groups, units)
t.contains <- units[sf::st_contains(groups, units), ]
t.contains <- units[unlist(sf::st_contains(groups, units)), ]
plot(t.contains$geometry)
plot(units$geometry)
nrow(t.contains) / nrow(units)
sf::st_intersects(t.contains, groups)
unlist(sf::st_intersects(t.contains, groups))
unique(unlist(sf::st_intersects(t.contains, groups)))
length(unique(unlist(sf::st_intersects(t.contains, groups))))
length(unique(unlist(sf::st_intersects(t.contains, groups)))) / nrow(groups))
length(unique(unlist(sf::st_intersects(t.contains, groups)))) / nrow(groups)
c(VALID = TRUE,
UNITS_IN_GROUPS = nrow(t.contains) / nrow(units),
GROUPS_IN_UNITS = length(unique(unlist(sf::st_intersects(t.contains, groups)))) / nrow(groups))
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- sf::st_intersection(units, groups)
t.intersection <- suppressWarnings(sf::st_intersection(units, groups))
sf::st_area(t.intersection)
sf::st_area(t.intersection)[match(units$GEOID_A, t.intersection$GEOID_A)]
head(sf::st_area(t.intersection)[match(units$GEOID_A, t.intersection$GEOID_A)])
head(sf::st_area(units))
head(sf::st_area(units)[match(units$GEOID_A, t.intersection$GEOID_A)])
t.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(units)[match(units$GEOID_A, t.intersection$GEOID_A)], ]
threshold = 0.1
t.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(units)[match(units$GEOID_A, t.intersection$GEOID_A)], ]
length(unique(t.intersection$GEOID_A)) / nrow(units)
length(unique(unlist(sf::st_intersects(t.intersection, groups)))) / nrow(groups)
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(units, groups))
i.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(groups[i.group, ])]
for (i.group in 1:nrow(groups)) {
i.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(groups[i.group, ])]
}
sf::st_area(t.intersection)
groups[i.group, ]
f::st_area(groups[i.group, ])
sf::st_area(groups[i.group, ])
threshold * sf::st_area(groups[i.group, ])
sf::st_area(t.intersection) >= threshold * sf::st_area(groups[i.group, ])
sum(sf::st_area(t.intersection) >= threshold * sf::st_area(groups[i.group, ]))
for (i.group in 1:nrow(groups)) {
i.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(groups[i.group, ]), ]
if (!exists("t.intersections")) {
t.intersections <- i.intersection
} else {
t.intersections <- rbind(t.intersections, i.intersection)
t.intersections <- t.intersections[!duplicated(t.intersections$GEOID), ]
}
}
View(t.intersections)
length(unique(t.intersections$GEOID_A)) / nrow(units)
length(unique(unlist(sf::st_intersects(t.intersections, groups)))) / nrow(groups))
length(unique(unlist(sf::st_intersects(t.intersections, groups)))) / nrow(groups)
check_overlap_units_groups <- function(units, groups, mode, threshold = 0.1) {
if (!"sf" %in% class(units) | !"sf" %in% class(groups)) {
stop("Arguments 'units' and 'groups' must be sf.")
}
if (!"sf" %in% class(units)) {
stop("Argument 'units' must be sf.")
}
if (!"sf" %in% class(groups)) {
stop("Argument 'groups' must be sf.")
}
if (!mode %in% c("INTERSECTS", "CONTAINS", "CONTAINS_THRESHOLD", "THRESHOLD_CONTAINED", "TWOWAY_THRESHOLD")) {
stop("Invalid 'mode' selection.")
}
if (toupper(mode) == "INTERSECTS") {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(groups, units))
if (nrow(t.intersection) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = sum(units$GEOID_A %in% t.intersection$GEOID_A) / nrow(units),
GROUPS_IN_UNITS = sum(groups$GEOID_B %in% t.intersection$GEOID_B) / nrow(groups)))
}
} else if (toupper(mode) == "CONTAINS") {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.contains <- units[unlist(sf::st_contains(groups, units)), ]
if (nrow(t.contains) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = nrow(t.contains) / nrow(units),
GROUPS_IN_UNITS = length(unique(unlist(sf::st_intersects(t.contains, groups)))) / nrow(groups)))
}
} else if (toupper(mode) == "CONTAINS_THRESHOLD") {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(units, groups))
t.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(units)[match(units$GEOID_A, t.intersection$GEOID_A)], ]
if (nrow(t.intersection) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = length(unique(t.intersection$GEOID_A)) / nrow(units),
GROUPS_IN_UNITS = length(unique(unlist(sf::st_intersects(t.intersection, groups)))) / nrow(groups)))
}
} else if (toupper(mode) == "THRESHOLD_CONTAINED") {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(units, groups))
for (i.group in 1:nrow(groups)) {
i.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(groups[i.group, ]), ]
if (!exists("t.intersections")) {
t.intersections <- i.intersection
} else {
t.intersections <- rbind(t.intersections, i.intersection)
t.intersections <- t.intersections[!duplicated(t.intersections$GEOID_A), ]
}
}
if (nrow(t.intersections) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = length(unique(t.intersections$GEOID_A)) / nrow(units),
GROUPS_IN_UNITS = length(unique(unlist(sf::st_intersects(t.intersections, groups)))) / nrow(groups)))
}
} else {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(units, groups))
i.contains_majority <- which(sf::st_area(t.intersection) >= threshold * sf::st_area(units)[match(units$GEOID_A, t.intersection$GEOID_A)])
for (i.group in 1:nrow(groups)) {
i.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(groups[i.group, ]), ]
if (!exists("t.intersections")) {
t.intersections <- i.intersection
} else {
t.intersections <- rbind(t.intersections, i.intersection)
t.intersections <- t.intersections[!duplicated(t.intersections$GEOID_A), ]
}
}
i.majorty_contained <- which(units$GEOID_A %in% t.intersections$GEOID_A)
t.twoway_threshold <- units[unique(c(i.contains_majority, i.majorty_contained)), ]
if (nrow(t.twoway_threshold) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = nrow(t.twoway_threshold) / nrow(units),
GROUPS_IN_UNITS = length(unique(unlist(sf::st_intersects(t.twoway_threshold, groups)))) / nrow(groups)))
}
}
}
check_overlap_units_groups(units, gropus, mode = "intersects")
check_overlap_units_groups(units, groups, mode = "intersects")
check_overlap_units_groups <- function(units, groups, mode, threshold = 0.1) {
if (!"sf" %in% class(units) | !"sf" %in% class(groups)) {
stop("Arguments 'units' and 'groups' must be sf.")
}
if (!"sf" %in% class(units)) {
stop("Argument 'units' must be sf.")
}
if (!"sf" %in% class(groups)) {
stop("Argument 'groups' must be sf.")
}
if (!toupper(mode) %in% c("INTERSECTS", "CONTAINS", "CONTAINS_THRESHOLD", "THRESHOLD_CONTAINED", "TWOWAY_THRESHOLD")) {
stop("Invalid 'mode' selection.")
}
if (toupper(mode) == "INTERSECTS") {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(groups, units))
if (nrow(t.intersection) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = sum(units$GEOID_A %in% t.intersection$GEOID_A) / nrow(units),
GROUPS_IN_UNITS = sum(groups$GEOID_B %in% t.intersection$GEOID_B) / nrow(groups)))
}
} else if (toupper(mode) == "CONTAINS") {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.contains <- units[unlist(sf::st_contains(groups, units)), ]
if (nrow(t.contains) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = nrow(t.contains) / nrow(units),
GROUPS_IN_UNITS = length(unique(unlist(sf::st_intersects(t.contains, groups)))) / nrow(groups)))
}
} else if (toupper(mode) == "CONTAINS_THRESHOLD") {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(units, groups))
t.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(units)[match(units$GEOID_A, t.intersection$GEOID_A)], ]
if (nrow(t.intersection) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = length(unique(t.intersection$GEOID_A)) / nrow(units),
GROUPS_IN_UNITS = length(unique(unlist(sf::st_intersects(t.intersection, groups)))) / nrow(groups)))
}
} else if (toupper(mode) == "THRESHOLD_CONTAINED") {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(units, groups))
for (i.group in 1:nrow(groups)) {
i.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(groups[i.group, ]), ]
if (!exists("t.intersections")) {
t.intersections <- i.intersection
} else {
t.intersections <- rbind(t.intersections, i.intersection)
t.intersections <- t.intersections[!duplicated(t.intersections$GEOID_A), ]
}
}
if (nrow(t.intersections) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = length(unique(t.intersections$GEOID_A)) / nrow(units),
GROUPS_IN_UNITS = length(unique(unlist(sf::st_intersects(t.intersections, groups)))) / nrow(groups)))
}
} else {
units$GEOID_A <- units$GEOID
groups$GEOID_B <- groups$GEOID
t.intersection <- suppressWarnings(sf::st_intersection(units, groups))
i.contains_majority <- which(sf::st_area(t.intersection) >= threshold * sf::st_area(units)[match(units$GEOID_A, t.intersection$GEOID_A)])
for (i.group in 1:nrow(groups)) {
i.intersection <- t.intersection[sf::st_area(t.intersection) >= threshold * sf::st_area(groups[i.group, ]), ]
if (!exists("t.intersections")) {
t.intersections <- i.intersection
} else {
t.intersections <- rbind(t.intersections, i.intersection)
t.intersections <- t.intersections[!duplicated(t.intersections$GEOID_A), ]
}
}
i.majorty_contained <- which(units$GEOID_A %in% t.intersections$GEOID_A)
t.twoway_threshold <- units[unique(c(i.contains_majority, i.majorty_contained)), ]
if (nrow(t.twoway_threshold) == 0) {
return(c(VALID = FALSE),
UNITS_IN_GROUPS = 0,
GROUPS_IN_UNITS = 0)
} else {
return(c(VALID = TRUE,
UNITS_IN_GROUPS = nrow(t.twoway_threshold) / nrow(units),
GROUPS_IN_UNITS = length(unique(unlist(sf::st_intersects(t.twoway_threshold, groups)))) / nrow(groups)))
}
}
}
check_overlap_units_groups(units, groups, mode = "intersects")
check_overlap_units_groups(units, groups, mode = "contains")
check_overlap_units_groups(units, groups, mode = "contains_threshold")
check_overlap_units_groups(units, groups, mode = "threshold_contained")
check_overlap_units_groups(units, groups, mode = "twoway_threshold")
devtools::document()
setwd("C:/Users/jremigio/OneDrive/Doctoral Studies/02 - Projects/25F-1 - Nucleus/Code/nucleus")
devtools::document()
devtools::check()
